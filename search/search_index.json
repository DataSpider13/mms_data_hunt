{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MeMeS Docs This is the documentation for the 2020 Heliophysics HackWeek to explore events noted by the SITL reports and within observations. Getting Set Up In order for all of us to collaborate on a project together, we need to ensure that we all are able to contribute within the same environment. I recommend creating a virtual environment for such a reason and I will step you thru this process to do so on your local device. Note The reason I prefer using Miniconda over Anaconda or Enthought's Canopy is two-fold: Miniconda only installs the minimum amount of Python packages needed to run the distribution; Miniconda would have initally faster imports for several packages as the pycache has not been built whereas Anaconda will be slower for that initial import to compile more of those packages. I do not use Canopy as it is not freely available for all features (mainly to add/remove Python packages at will). Obtain and Install Miniconda Miniconda can be downloaded from here: https://docs.conda.io/en/latest/miniconda.html . For Linux/Mac Operating Systems, I recommend using the files that download a .sh file. This can then be run from the Terminal/Command Prompt. For Windows, I will warn you to uninstall any prior installations of Python separate from ArcGIS and/or other self-contained installations. When installing packages, the exact location to install these gets clobbered within Windows installations that have multiple \"Python\"s. Miniconda, unlike Anaconda, will only install the Python .exe file. Ancaconda allows you to install the Anaconda Navigator which, in my experience, is confusing. Follow the installation instructions: Linux/Mac, at the end, be sure to allow the installer to run the init script which will place the proper lines in your shell's rc file. You can find which shell you are running by the command: echo $0 Windows, you will want to install from the .exe file and then use the Anaconda Command Prompt to use the modified environment that recognizes the proper Python installation. Test your default installation. In order to test your installation, type python from the Terminal/Anaconda Prompt and you should see something similar to: Python 3.8.3 [Clang 10.0.0 ] :: Anaconda, Inc. Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> The >>> shows that you are actually running the Python interpreter. This is what we want to see. To exit, type exit() and hit enter. Please refer to this resource for more links to get familiar with Python programming. Set Up a Virtual Environment I recommend doing the following step in order to update the installers and default environment from the Terminal/Anaconda Command Prompt: conda update conda conda install pip virtualenv This updates the conda installer as well as installs a separate installer ( pip ) and the Python package that allows us to create virtual environments ( virtualenv ). Clone the GitHub Repository Most Linux/Mac systems already come with Git installed. Windows, you will want to download and install Git. In order to clone the repository, you need to execute the following command (Windows, do this from the Git Bash which is separate from the Anaconda Command Prompt ): git clone https://github.com/heliohackweek/mms_data_hunt.git There might be some configuration needed in order to do this, but it will \"copy\" the code into the current directory that you are at. Windows, you will need to know where that is or cd to a location before cloning so that you can work with the copied files. Please refer to this resource for more links to get familiar with Git. Test environment on your local device. In the files that you cloned, there is a test folder that contains a script that will allow one to ensure that their environment is setup properly. To run this: python /location/of/mms_data_hunt/test It verifies that all the necessary imports are installed. Set Up for Remote Systems On other systems, you will most likely be provided a Python installation that has been built or is customized for you. Here is my recommendations for getting started for those systems. Log into the system. Load Python environment using (module load; sourcing a module file). Clone the GitHub Repository. Test environment on the remote system.","title":"Overview"},{"location":"#memes-docs","text":"This is the documentation for the 2020 Heliophysics HackWeek to explore events noted by the SITL reports and within observations.","title":"MeMeS Docs"},{"location":"#getting-set-up","text":"In order for all of us to collaborate on a project together, we need to ensure that we all are able to contribute within the same environment. I recommend creating a virtual environment for such a reason and I will step you thru this process to do so on your local device. Note The reason I prefer using Miniconda over Anaconda or Enthought's Canopy is two-fold: Miniconda only installs the minimum amount of Python packages needed to run the distribution; Miniconda would have initally faster imports for several packages as the pycache has not been built whereas Anaconda will be slower for that initial import to compile more of those packages. I do not use Canopy as it is not freely available for all features (mainly to add/remove Python packages at will). Obtain and Install Miniconda Miniconda can be downloaded from here: https://docs.conda.io/en/latest/miniconda.html . For Linux/Mac Operating Systems, I recommend using the files that download a .sh file. This can then be run from the Terminal/Command Prompt. For Windows, I will warn you to uninstall any prior installations of Python separate from ArcGIS and/or other self-contained installations. When installing packages, the exact location to install these gets clobbered within Windows installations that have multiple \"Python\"s. Miniconda, unlike Anaconda, will only install the Python .exe file. Ancaconda allows you to install the Anaconda Navigator which, in my experience, is confusing. Follow the installation instructions: Linux/Mac, at the end, be sure to allow the installer to run the init script which will place the proper lines in your shell's rc file. You can find which shell you are running by the command: echo $0 Windows, you will want to install from the .exe file and then use the Anaconda Command Prompt to use the modified environment that recognizes the proper Python installation. Test your default installation. In order to test your installation, type python from the Terminal/Anaconda Prompt and you should see something similar to: Python 3.8.3 [Clang 10.0.0 ] :: Anaconda, Inc. Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> The >>> shows that you are actually running the Python interpreter. This is what we want to see. To exit, type exit() and hit enter. Please refer to this resource for more links to get familiar with Python programming. Set Up a Virtual Environment I recommend doing the following step in order to update the installers and default environment from the Terminal/Anaconda Command Prompt: conda update conda conda install pip virtualenv This updates the conda installer as well as installs a separate installer ( pip ) and the Python package that allows us to create virtual environments ( virtualenv ). Clone the GitHub Repository Most Linux/Mac systems already come with Git installed. Windows, you will want to download and install Git. In order to clone the repository, you need to execute the following command (Windows, do this from the Git Bash which is separate from the Anaconda Command Prompt ): git clone https://github.com/heliohackweek/mms_data_hunt.git There might be some configuration needed in order to do this, but it will \"copy\" the code into the current directory that you are at. Windows, you will need to know where that is or cd to a location before cloning so that you can work with the copied files. Please refer to this resource for more links to get familiar with Git. Test environment on your local device. In the files that you cloned, there is a test folder that contains a script that will allow one to ensure that their environment is setup properly. To run this: python /location/of/mms_data_hunt/test It verifies that all the necessary imports are installed.","title":"Getting Set Up"},{"location":"#set-up-for-remote-systems","text":"On other systems, you will most likely be provided a Python installation that has been built or is customized for you. Here is my recommendations for getting started for those systems. Log into the system. Load Python environment using (module load; sourcing a module file). Clone the GitHub Repository. Test environment on the remote system.","title":"Set Up for Remote Systems"},{"location":"hw/","text":"MMS Data Hunt Project This Helio HackWeek project aims at finding events within observational data from Scientists in the Loop (SITL) reports to better equip researchers of finding overlooked or similar events by extending the requested functionality. Challenges/Tasks: SITL Reports Web Search a. Building the database. Retrieve ASCII reports from Berkely hopefully from some type of RESTful API. Parse through reports to create a language learning set to pick up on mispelled events, case sensitivity, and typographic errors. Find occurances of reported BBF and DF events. Store results in a SQL-less database for future use. Automate process for future reports as well as process all remaining reports. out of scope: create a standardized reporting mechanism or format b. Frontend work Website with search that queries database base upon event type, date range, or latest N events. API underneath website so researchers can grab data from database using HTTP methods Visually map events to xy and yz planes for further research Add functionality of mapping/visualizations to show data layers or with slight transparency out of scope: extend to produce a catalog of all events reported Event Finder a. Build a Python package to search MMS data for specific events (BBF & DF) Use pyspedas to retrieve/stream data for specific dates and times reported from sample CSV files from database of SITL reports Unsure about specific types of observations needed to identify these events Data format retrieved? Is is a Pandas dataframe? Manipulate to identify event duration, magnatude, location, and observational files used. Add event information to database as well as references to data, imagery, and other information (metadata or resources) b. Use ML to find similar events Once a small subset of events have been confirmed from the data, a training set will be created for each event type Use of tensorflow to produce similar events within the spanse of observational records Optimize algorithm used to optimize resource use c. Use GPU processing to optimize ML techniques Use RAPIDS on NVIDIA resources to expedite processing of data for events Build optimized algorithms to sift through large amounts of data for analysis","title":"HackWeek Project"},{"location":"hw/#mms-data-hunt-project","text":"This Helio HackWeek project aims at finding events within observational data from Scientists in the Loop (SITL) reports to better equip researchers of finding overlooked or similar events by extending the requested functionality. Challenges/Tasks: SITL Reports Web Search a. Building the database. Retrieve ASCII reports from Berkely hopefully from some type of RESTful API. Parse through reports to create a language learning set to pick up on mispelled events, case sensitivity, and typographic errors. Find occurances of reported BBF and DF events. Store results in a SQL-less database for future use. Automate process for future reports as well as process all remaining reports. out of scope: create a standardized reporting mechanism or format b. Frontend work Website with search that queries database base upon event type, date range, or latest N events. API underneath website so researchers can grab data from database using HTTP methods Visually map events to xy and yz planes for further research Add functionality of mapping/visualizations to show data layers or with slight transparency out of scope: extend to produce a catalog of all events reported Event Finder a. Build a Python package to search MMS data for specific events (BBF & DF) Use pyspedas to retrieve/stream data for specific dates and times reported from sample CSV files from database of SITL reports Unsure about specific types of observations needed to identify these events Data format retrieved? Is is a Pandas dataframe? Manipulate to identify event duration, magnatude, location, and observational files used. Add event information to database as well as references to data, imagery, and other information (metadata or resources) b. Use ML to find similar events Once a small subset of events have been confirmed from the data, a training set will be created for each event type Use of tensorflow to produce similar events within the spanse of observational records Optimize algorithm used to optimize resource use c. Use GPU processing to optimize ML techniques Use RAPIDS on NVIDIA resources to expedite processing of data for events Build optimized algorithms to sift through large amounts of data for analysis","title":"MMS Data Hunt Project"},{"location":"mms/","text":"Magnetospheric MultiScale (MMS) Mission Quick Overview References Quick Overview MMS, a missions consisting of four identical spacecraft, was launched in 2015. This mission orbit around the Earth to study magnetic reconnection. For more information regarding the theory of magnetic reconnection, please see this for a introduction and this for a more detailed description. But magnetic reconnection is not what we are attempting to find in this project. Bursty Bulk Flows (BBF) Dipolarization Fronts (DF) References Main NASA Website BBF/DF Article","title":"MMS Mission"},{"location":"mms/#magnetospheric-multiscale-mms-mission","text":"Quick Overview References","title":"Magnetospheric MultiScale (MMS) Mission"},{"location":"mms/#quick-overview","text":"MMS, a missions consisting of four identical spacecraft, was launched in 2015. This mission orbit around the Earth to study magnetic reconnection. For more information regarding the theory of magnetic reconnection, please see this for a introduction and this for a more detailed description. But magnetic reconnection is not what we are attempting to find in this project.","title":"Quick Overview"},{"location":"mms/#bursty-bulk-flows-bbf","text":"","title":"Bursty Bulk Flows (BBF)"},{"location":"mms/#dipolarization-fronts-df","text":"","title":"Dipolarization Fronts (DF)"},{"location":"mms/#references","text":"Main NASA Website BBF/DF Article","title":"References"}]}